{"componentChunkName":"component---src-pages-01-prereq-crc-installation-mdx","path":"/01-prereq/crc_installation/","result":{"pageContext":{"frontmatter":{"title":"CodeReady Containers","description":"CodeReady Containers"},"relativePagePath":"/01-prereq/crc_installation.mdx","titleType":"page","MdxNode":{"id":"ec98fea7-2b07-544b-b6e6-4634ceb78c29","children":[],"parent":"96e315a9-7bbc-5dca-b5a8-3961602d23a1","internal":{"content":"---\ntitle: CodeReady Containers\ndescription: CodeReady Containers\n---\n\n## What is CRC?\n\nCodeReady Containers is a minimal, preconfigured OpenShift 4.1 cluster designed to run on your local workstation as a development environment for OpenShift is [CodeReady Containers](https://github.com/code-ready/crc) (CRC)\n\nSimilar to Minikube in concept, CRC provides a cloud like environment locally, to create and deploy an OpenShift cluster for development and testing purposes.\n\nHere, we will cover some common CRC operations, including deploying SPM to the CRC environment. We will be using the same helm charts produced in the previous [Preparing Helm charts](/04-deployment/hc_deployment) section.\n\nA full getting started guide for CRC can be found at [this link](https://access.redhat.com/documentation/en-us/red_hat_codeready_containers/1.8/html/getting_started_guide/index)\n\n<InlineNotification>\n\n**Note:**  Cúram SPM does not provide official support of OpenShift. All the references to OpenShift and CRC should be considered as an Early Adopter Release.\n\n</InlineNotification>\n\n**System Requirements**:\n\n- Detailed system requirements can be found [in the CRC documentation](https://code-ready.github.io/crc/#minimum-system-requirements_gsg).\nCRC needs to be able to allocate a minimum of 9GB RAM to its VM.\nIt is recommended your workstation have at least 16GB to operate, some workloads may require more.\n\n## Installation of CRC\n\nYou will need to create an account at [RedHat Cloud](https://www.redhat.com/).\n\nCreate a `$CRC_HOME` folder to use for the purposes of the installation.\nDownload the installation archive from [latest release](https://cloud.redhat.com/openshift/install/crc/installer-provisioned) to `$CRC_HOME` and extract the archive.\nOn the same page download your pull secret to `$CRC_HOME`. At the time of writing the `latest release` is `1.10.0`.\n\n```shell\ntar -xvf crc-macos-amd64.tar.xz\n```\n\n<InlineNotification>\n\n**Note:**  Here we have two options, add the binary to the `PATH` environment variable, or move it to `/usr/local/bin/`\n\n</InlineNotification>\n\n<Tabs>\n\n<Tab label=\"Add to the PATH\">\n<Row>\n<Column>\n\n`export PATH=$CRC_HOME/crc-macos-1.10.0-amd64:$PATH`\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"/usr/bin/local \">\n<Row>\n<Column>\n\n`mv $CRC_HOME/crc-macos-1.10.0-amd64/crc /usr/local/bin`\n\n</Column>\n</Row>\n</Tab>\n</Tabs>\n\nWhichever option you choose, you should now have crc in your executable path, to test this run:\n\n```shell\ncrc version\n```\n\nThe output should be similar to:\n\n```\ncrc version: 1.10.0+9025021\nOpenShift version: 4.4.3 (embedded in binary)\n```\n\n## Setting up CRC\n\nThe first step is to configure the prerequisites for the OpenShift cluster, including taking control of your hosts and resolver files to provide access to the CRC cluster.\nTo do this run the following command, providing the workstation administrator password as required.\nThis procedure will also create the ~/.crc directory if it does not already exist.\n\n```shell\ncrc setup\n```\n\nNow that the basic configuration is complete, we can edit the configuration further to change the memory limit and add the path to the pull secret file downloaded previously.\nWe will also set the cpus to 6:\n\n```shell\ncrc config set memory 32768\ncrc config set cpus 6\ncrc config set pull-secret-file $CRC_HOME/pull-secret.txt\n```\n\n<InlineNotification>\n\n**Note:**  While CRC's minimum memory allocation requirement is 8GB, only a single replica Curam deployment can be achieved using this.\nWe suggest you allocate as many resources as available.\nThe greater the workload the greater the memory and processor requirements.\nAny changes to the crc config require you to delete the cluster and start a new one.\n\n</InlineNotification>\n\nYou can always check the configured options of ’crc’ with:\n\n```shell\ncrc config view\n```\n\nAfter setup is complete, the cluster could be started with 6 CPUs.\n\n```shell\ncrc start\n```\n\nThis will output something similar to:\n\n```\nlevel=info msg=\"Checking if oc binary is cached\"\n...\n...\n...\nlevel=info msg=\"To access the cluster, first set up your environment by following 'crc oc-env' instructions\"\nlevel=info msg=\"Then you can access it by running 'oc login -u developer -p developer https://api.crc.testing:6443'\"\nlevel=info msg=\"To login as an admin, run 'oc login -u kubeadmin -p YourPassWordHere https://api.crc.testing:6443'\"\n...\n...\n```\n\nPlease note the `kubeadmin` and `developer` credentials for later use.\n\n<InlineNotification>\n\n**Note:**  For the rest of the guide you can substitute the credentials you received when you started your cluster for $KUBEADMN_PSWD and $KUBEDEVEL_PSWD.\nAlternatively these credentials will be returned by the `crc console --credentials` commands.\nThis guide will be using $KUBEDEVEL_PSWD and $KUBEADMN_PSWD environment variables.\nYou may find it convenient to to the same, so you can copy and paste commands without having to switch values:\n\n`export KUBEADMN_PSWD=yourKubeAdminPassword`\n\n`export KUBEDEVEL_PSWD=yourKubeDeveloperPassword`\n\n</InlineNotification>\n\nNext we will set up the OpenShift Client `oc` which is used to administer the CRC cluster by running the following two commands:\n\n```shell\ncrc oc-env\neval $(crc oc-env)\n```\n\nIf required, you can stop the cluster using:\n\n```shell\ncrc stop\n```\n\nOr delete it using:\n\n```shell\ncrc delete\n```\n\n## Creating a CRC project\n\nWe will create a project for our SPM deployment, again we will use an environment variable for added convenience when following the guide.\n\nCreate the environment variable, you can set to value to anything you like, but it should consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc\"):\n\n```shell\nexport releasename=\"spm-deploy\"\n```\n\nLogin as kubeadmin:\n\n```shell\noc login -u kubeadmin -p $KUBEADMN_PSWD https://api.crc.testing:6443\n```\n\nCreate the project:\n\n```shell\noc adm new-project $releasename\n```\n\nAnd switch kubernetes context to the new project:\n\n```shell\nkubectl config set-context --current --namespace $releasename\n```\n\n## Deployment Process\n\nCreation of a Security Context Constraint (SCC).\nThis SCC allows DB2 and MQ images to run as they require certain permissions, which are by default blocked in OpenShift.\n\nWe have provided a shell script to configure the SCC, located at `$SPM_HOME/helm-charts/spm/prereqs` apply the policy by running the script as follows:\n\n```shell\ncd $SPM_HOME/helm-charts/spm/prereqs\n./createSCC.sh -n $releasename\n```\n\nEnable the Image Registry default route\n\n```shell\noc patch configs.imageregistry.operator.openshift.io/cluster --type merge -p '{\"spec\":{\"defaultRoute\":true}}'\n\n```\n\nAdd relevant roles to user\n\n```shell\noc get pods -n openshift-image-registry\noc policy add-role-to-user registry-viewer kube:admin\noc adm policy add-cluster-role-to-user registry-viewer kube:admin\n```\n\n<InlineNotification>\n\n**Note:**  This will overwrite any existing policy with the same name.\n\nIf policy already exists, add system:serviceaccount:${releasename}:default to the users array in the policy by editing the policy YAML or running the command below:\n\n`oc adm policy add-scc-to-user spm-dev-scc -z system:serviceaccount:${releasename}:default`\n\n</InlineNotification>\n\nOnce ran, you can verify that the SCC for SPM has been created:\n\n```\nkubectl get scc\nNAME               AGE\nanyuid             1d\nhostaccess         1d\nhostmount-anyuid   1d\nhostnetwork        1d\nnode-exporter      1d\nnonroot            1d\nprivileged         1d\nrestricted         1d\nspm-dev-scc        1m\n```\n","type":"Mdx","contentDigest":"ad21b61c63b816656a90df969a8a0ffe","counter":120,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"CodeReady Containers","description":"CodeReady Containers"},"exports":{},"rawBody":"---\ntitle: CodeReady Containers\ndescription: CodeReady Containers\n---\n\n## What is CRC?\n\nCodeReady Containers is a minimal, preconfigured OpenShift 4.1 cluster designed to run on your local workstation as a development environment for OpenShift is [CodeReady Containers](https://github.com/code-ready/crc) (CRC)\n\nSimilar to Minikube in concept, CRC provides a cloud like environment locally, to create and deploy an OpenShift cluster for development and testing purposes.\n\nHere, we will cover some common CRC operations, including deploying SPM to the CRC environment. We will be using the same helm charts produced in the previous [Preparing Helm charts](/04-deployment/hc_deployment) section.\n\nA full getting started guide for CRC can be found at [this link](https://access.redhat.com/documentation/en-us/red_hat_codeready_containers/1.8/html/getting_started_guide/index)\n\n<InlineNotification>\n\n**Note:**  Cúram SPM does not provide official support of OpenShift. All the references to OpenShift and CRC should be considered as an Early Adopter Release.\n\n</InlineNotification>\n\n**System Requirements**:\n\n- Detailed system requirements can be found [in the CRC documentation](https://code-ready.github.io/crc/#minimum-system-requirements_gsg).\nCRC needs to be able to allocate a minimum of 9GB RAM to its VM.\nIt is recommended your workstation have at least 16GB to operate, some workloads may require more.\n\n## Installation of CRC\n\nYou will need to create an account at [RedHat Cloud](https://www.redhat.com/).\n\nCreate a `$CRC_HOME` folder to use for the purposes of the installation.\nDownload the installation archive from [latest release](https://cloud.redhat.com/openshift/install/crc/installer-provisioned) to `$CRC_HOME` and extract the archive.\nOn the same page download your pull secret to `$CRC_HOME`. At the time of writing the `latest release` is `1.10.0`.\n\n```shell\ntar -xvf crc-macos-amd64.tar.xz\n```\n\n<InlineNotification>\n\n**Note:**  Here we have two options, add the binary to the `PATH` environment variable, or move it to `/usr/local/bin/`\n\n</InlineNotification>\n\n<Tabs>\n\n<Tab label=\"Add to the PATH\">\n<Row>\n<Column>\n\n`export PATH=$CRC_HOME/crc-macos-1.10.0-amd64:$PATH`\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"/usr/bin/local \">\n<Row>\n<Column>\n\n`mv $CRC_HOME/crc-macos-1.10.0-amd64/crc /usr/local/bin`\n\n</Column>\n</Row>\n</Tab>\n</Tabs>\n\nWhichever option you choose, you should now have crc in your executable path, to test this run:\n\n```shell\ncrc version\n```\n\nThe output should be similar to:\n\n```\ncrc version: 1.10.0+9025021\nOpenShift version: 4.4.3 (embedded in binary)\n```\n\n## Setting up CRC\n\nThe first step is to configure the prerequisites for the OpenShift cluster, including taking control of your hosts and resolver files to provide access to the CRC cluster.\nTo do this run the following command, providing the workstation administrator password as required.\nThis procedure will also create the ~/.crc directory if it does not already exist.\n\n```shell\ncrc setup\n```\n\nNow that the basic configuration is complete, we can edit the configuration further to change the memory limit and add the path to the pull secret file downloaded previously.\nWe will also set the cpus to 6:\n\n```shell\ncrc config set memory 32768\ncrc config set cpus 6\ncrc config set pull-secret-file $CRC_HOME/pull-secret.txt\n```\n\n<InlineNotification>\n\n**Note:**  While CRC's minimum memory allocation requirement is 8GB, only a single replica Curam deployment can be achieved using this.\nWe suggest you allocate as many resources as available.\nThe greater the workload the greater the memory and processor requirements.\nAny changes to the crc config require you to delete the cluster and start a new one.\n\n</InlineNotification>\n\nYou can always check the configured options of ’crc’ with:\n\n```shell\ncrc config view\n```\n\nAfter setup is complete, the cluster could be started with 6 CPUs.\n\n```shell\ncrc start\n```\n\nThis will output something similar to:\n\n```\nlevel=info msg=\"Checking if oc binary is cached\"\n...\n...\n...\nlevel=info msg=\"To access the cluster, first set up your environment by following 'crc oc-env' instructions\"\nlevel=info msg=\"Then you can access it by running 'oc login -u developer -p developer https://api.crc.testing:6443'\"\nlevel=info msg=\"To login as an admin, run 'oc login -u kubeadmin -p YourPassWordHere https://api.crc.testing:6443'\"\n...\n...\n```\n\nPlease note the `kubeadmin` and `developer` credentials for later use.\n\n<InlineNotification>\n\n**Note:**  For the rest of the guide you can substitute the credentials you received when you started your cluster for $KUBEADMN_PSWD and $KUBEDEVEL_PSWD.\nAlternatively these credentials will be returned by the `crc console --credentials` commands.\nThis guide will be using $KUBEDEVEL_PSWD and $KUBEADMN_PSWD environment variables.\nYou may find it convenient to to the same, so you can copy and paste commands without having to switch values:\n\n`export KUBEADMN_PSWD=yourKubeAdminPassword`\n\n`export KUBEDEVEL_PSWD=yourKubeDeveloperPassword`\n\n</InlineNotification>\n\nNext we will set up the OpenShift Client `oc` which is used to administer the CRC cluster by running the following two commands:\n\n```shell\ncrc oc-env\neval $(crc oc-env)\n```\n\nIf required, you can stop the cluster using:\n\n```shell\ncrc stop\n```\n\nOr delete it using:\n\n```shell\ncrc delete\n```\n\n## Creating a CRC project\n\nWe will create a project for our SPM deployment, again we will use an environment variable for added convenience when following the guide.\n\nCreate the environment variable, you can set to value to anything you like, but it should consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc\"):\n\n```shell\nexport releasename=\"spm-deploy\"\n```\n\nLogin as kubeadmin:\n\n```shell\noc login -u kubeadmin -p $KUBEADMN_PSWD https://api.crc.testing:6443\n```\n\nCreate the project:\n\n```shell\noc adm new-project $releasename\n```\n\nAnd switch kubernetes context to the new project:\n\n```shell\nkubectl config set-context --current --namespace $releasename\n```\n\n## Deployment Process\n\nCreation of a Security Context Constraint (SCC).\nThis SCC allows DB2 and MQ images to run as they require certain permissions, which are by default blocked in OpenShift.\n\nWe have provided a shell script to configure the SCC, located at `$SPM_HOME/helm-charts/spm/prereqs` apply the policy by running the script as follows:\n\n```shell\ncd $SPM_HOME/helm-charts/spm/prereqs\n./createSCC.sh -n $releasename\n```\n\nEnable the Image Registry default route\n\n```shell\noc patch configs.imageregistry.operator.openshift.io/cluster --type merge -p '{\"spec\":{\"defaultRoute\":true}}'\n\n```\n\nAdd relevant roles to user\n\n```shell\noc get pods -n openshift-image-registry\noc policy add-role-to-user registry-viewer kube:admin\noc adm policy add-cluster-role-to-user registry-viewer kube:admin\n```\n\n<InlineNotification>\n\n**Note:**  This will overwrite any existing policy with the same name.\n\nIf policy already exists, add system:serviceaccount:${releasename}:default to the users array in the policy by editing the policy YAML or running the command below:\n\n`oc adm policy add-scc-to-user spm-dev-scc -z system:serviceaccount:${releasename}:default`\n\n</InlineNotification>\n\nOnce ran, you can verify that the SCC for SPM has been created:\n\n```\nkubectl get scc\nNAME               AGE\nanyuid             1d\nhostaccess         1d\nhostmount-anyuid   1d\nhostnetwork        1d\nnode-exporter      1d\nnonroot            1d\nprivileged         1d\nrestricted         1d\nspm-dev-scc        1m\n```\n","fileAbsolutePath":"/home/travis/build/IBM/spm-kubernetes/src/pages/01-prereq/crc_installation.mdx"}}}}