{"componentChunkName":"component---src-pages-07-supporting-infrastructure-batch-mdx","path":"/07-supporting-infrastructure/batch/","result":{"pageContext":{"frontmatter":{"title":"SPM batch processing on Kubernetes","description":"SPM batch processing on Kubernetes"},"relativePagePath":"/07-supporting-infrastructure/batch.mdx","titleType":"page","MdxNode":{"id":"c844fa53-7ef6-5f64-9465-2d5d22c346b9","children":[],"parent":"4e824498-e96c-51ed-9e3a-040441210190","internal":{"content":"---\ntitle: SPM batch processing on Kubernetes\ndescription: SPM batch processing on Kubernetes\n---\n\n## How batch streaming is deployed in IBM® Cloud™ Kubernetes Services (IKS)\n\nSPM on Kubernetes supports a different model for batch processing in IKS, where, as outlined earlier in this runbook, SPM batch processing can be built and deployed into its own pod.\nBy running SPM batch processing in its own pod, the pod can leverage the benefits of flexibility, elasticity, efficiency and the strategic value offered by cloud native architecture.\n\n### What is batch streaming\n\nThe batch streaming infrastructure provides a straightforward mechanism to implement a batch process so that it can be run in parallel (streams) across multiple pods.\nFor example, if we wanted to issue payments, the chunker identifies all the cases to be paid and the stream would process a case and issue the the payment(s) that are due.\n\n<InlineNotification>\n\n**Note:** For more information, see [Batch Streaming Architecture](https://www.ibm.com/support/knowledgecenter/SS8S5A_7.0.10/com.ibm.curam.content.doc/BatchPerformanceMechanisms/c_BATCHPER_Architecture1AdditionalInformation1.html)\n\n</InlineNotification>\n\n### Setting up Batch Streaming yaml files\n\nOutlined below is an example for the steps required to set up Batch Streaming.\nFor this example we are going to use the bulk reassessment of food assistance case types.\n\nThe first stage is to set up a new yaml file for the streaming and chunking batch processing.\n\n<InlineNotification>\n\n**Note:** No SPM default installation settings were changed.\n\n</InlineNotification>\n\n```shell\nexport NAMESPACE=\nexport releasename=\nkubectl create job --from=cronjob/$releasename-batch -n $NAMESPACE -o yaml --dry-run testjob > yaml_chart_name.yaml\n```\n\n<InlineNotification>\n\n**Note:** where\n\n* NAMESPACE is the namespace where you want to run the batch processing\n* releaseName is the name of the release you are using\n* yaml_chart_name is the name of the chart you are creating\n  * It is recommended that a new chart is created for each process, e.g. stream_foodassistance, chunker_foodassistance\n\n</InlineNotification>\n\nA coresponding `yaml` file is created.\nOpen the yaml file in an editor e.g  vi `chunker_foodassistance.yaml`\n\nIn the yaml file, add the following lines after the `containers` section:\n\n<Tabs>\n\n<Tab label=\"Chunker\">\n<Row>\n<Column>\n\n```yaml\nspec:\n  backoffLimit: 5\n  template:\n    metadata:\n      creationTimestamp: null\n    spec:\n      containers:\n      - command:\n          - build.sh\n          - runbatch\n        args:\n          - -Dcuram.jmx.output_statistics_timer_enabled=true\n          - -Dcuram.jmx.output_statistics_timer_folder=/tmp\n          - -Dcuram.jmx.output_statistics_timer_period=60000\n          - -Dbatch.program=curam.core.sl.infrastructure.assessment.intf.CREOLEBulkCaseChunkReassessmentByProduct.process\n          - -Dbatch.parameters=\"productID=4200\"\n        env:\n          - name: ANT_OPTS\n            value: -Xgcpolicy:gencon -Xverbosegclog:/tmp/GCLogs_chunker.log\n        image: ......\n\n```\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"Stream\">\n<Row>\n<Column>\n\n```yaml\nspec:\n  backoffLimit: 5\n  template:\n    metadata:\n      creationTimestamp: null\n    spec:\n      containers:\n      - command:\n          - build.sh\n          - runbatch\n        args:\n          - -Dcuram.jmx.output_statistics_timer_enabled=true\n          - -Dcuram.jmx.output_statistics_timer_folder=/tmp\n          - -Dcuram.jmx.output_statistics_timer_period=60000\n          - -Dbatch.program=curam.core.sl.infrastructure.assessment.intf.CREOLEBulkCaseChunkReassessmentStream.process\n        env:\n          - name: ANT_OPTS\n            value: -Xgcpolicy:gencon -Xverbosegclog:/tmp/GCLogs_stream.log\n        image: ......\n\n```\n\n</Column>\n</Row>\n</Tab>\n\n</Tabs>\n\nAt this point you should now have a yaml file for a chunker and streamer for bulk reassessment of food assistance case types.\n\n### Running batch streaming yaml files\n\nTo orchestrate the batch process, run the following command and repeat for the chunker and streamer(s).\n\n```shell\nkubectl create -f yaml_chart_name.yaml -n $NAMESPACE\n```\n\n![spm batch on kubernetes](../../images/spm_batch_processing_on_kubernetes.png)\n<Caption>\n\n*Figure 1:* SPM batch processing on Kuberbetes\n\n</Caption>\n\n<InlineNotification>\n\n**Note:** where\n\n* NAMESPACE is the namespace where you want to run the batch processing\n* yaml_chart_name is the name of the chart you are creating\n\n</InlineNotification>\n\n### Post batch processing\n\nWhen the batch processes complete, the pods remain behind and are not shut down.\n\nThe batch pods that are created for batch streaming are on demand. After the batch process finishes, the related pods should be destroyed to free resources in the IKS cluster.\n","type":"Mdx","contentDigest":"e2d00075ab8ae3985f401598c7c58f7d","counter":138,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"SPM batch processing on Kubernetes","description":"SPM batch processing on Kubernetes"},"exports":{},"rawBody":"---\ntitle: SPM batch processing on Kubernetes\ndescription: SPM batch processing on Kubernetes\n---\n\n## How batch streaming is deployed in IBM® Cloud™ Kubernetes Services (IKS)\n\nSPM on Kubernetes supports a different model for batch processing in IKS, where, as outlined earlier in this runbook, SPM batch processing can be built and deployed into its own pod.\nBy running SPM batch processing in its own pod, the pod can leverage the benefits of flexibility, elasticity, efficiency and the strategic value offered by cloud native architecture.\n\n### What is batch streaming\n\nThe batch streaming infrastructure provides a straightforward mechanism to implement a batch process so that it can be run in parallel (streams) across multiple pods.\nFor example, if we wanted to issue payments, the chunker identifies all the cases to be paid and the stream would process a case and issue the the payment(s) that are due.\n\n<InlineNotification>\n\n**Note:** For more information, see [Batch Streaming Architecture](https://www.ibm.com/support/knowledgecenter/SS8S5A_7.0.10/com.ibm.curam.content.doc/BatchPerformanceMechanisms/c_BATCHPER_Architecture1AdditionalInformation1.html)\n\n</InlineNotification>\n\n### Setting up Batch Streaming yaml files\n\nOutlined below is an example for the steps required to set up Batch Streaming.\nFor this example we are going to use the bulk reassessment of food assistance case types.\n\nThe first stage is to set up a new yaml file for the streaming and chunking batch processing.\n\n<InlineNotification>\n\n**Note:** No SPM default installation settings were changed.\n\n</InlineNotification>\n\n```shell\nexport NAMESPACE=\nexport releasename=\nkubectl create job --from=cronjob/$releasename-batch -n $NAMESPACE -o yaml --dry-run testjob > yaml_chart_name.yaml\n```\n\n<InlineNotification>\n\n**Note:** where\n\n* NAMESPACE is the namespace where you want to run the batch processing\n* releaseName is the name of the release you are using\n* yaml_chart_name is the name of the chart you are creating\n  * It is recommended that a new chart is created for each process, e.g. stream_foodassistance, chunker_foodassistance\n\n</InlineNotification>\n\nA coresponding `yaml` file is created.\nOpen the yaml file in an editor e.g  vi `chunker_foodassistance.yaml`\n\nIn the yaml file, add the following lines after the `containers` section:\n\n<Tabs>\n\n<Tab label=\"Chunker\">\n<Row>\n<Column>\n\n```yaml\nspec:\n  backoffLimit: 5\n  template:\n    metadata:\n      creationTimestamp: null\n    spec:\n      containers:\n      - command:\n          - build.sh\n          - runbatch\n        args:\n          - -Dcuram.jmx.output_statistics_timer_enabled=true\n          - -Dcuram.jmx.output_statistics_timer_folder=/tmp\n          - -Dcuram.jmx.output_statistics_timer_period=60000\n          - -Dbatch.program=curam.core.sl.infrastructure.assessment.intf.CREOLEBulkCaseChunkReassessmentByProduct.process\n          - -Dbatch.parameters=\"productID=4200\"\n        env:\n          - name: ANT_OPTS\n            value: -Xgcpolicy:gencon -Xverbosegclog:/tmp/GCLogs_chunker.log\n        image: ......\n\n```\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"Stream\">\n<Row>\n<Column>\n\n```yaml\nspec:\n  backoffLimit: 5\n  template:\n    metadata:\n      creationTimestamp: null\n    spec:\n      containers:\n      - command:\n          - build.sh\n          - runbatch\n        args:\n          - -Dcuram.jmx.output_statistics_timer_enabled=true\n          - -Dcuram.jmx.output_statistics_timer_folder=/tmp\n          - -Dcuram.jmx.output_statistics_timer_period=60000\n          - -Dbatch.program=curam.core.sl.infrastructure.assessment.intf.CREOLEBulkCaseChunkReassessmentStream.process\n        env:\n          - name: ANT_OPTS\n            value: -Xgcpolicy:gencon -Xverbosegclog:/tmp/GCLogs_stream.log\n        image: ......\n\n```\n\n</Column>\n</Row>\n</Tab>\n\n</Tabs>\n\nAt this point you should now have a yaml file for a chunker and streamer for bulk reassessment of food assistance case types.\n\n### Running batch streaming yaml files\n\nTo orchestrate the batch process, run the following command and repeat for the chunker and streamer(s).\n\n```shell\nkubectl create -f yaml_chart_name.yaml -n $NAMESPACE\n```\n\n![spm batch on kubernetes](../../images/spm_batch_processing_on_kubernetes.png)\n<Caption>\n\n*Figure 1:* SPM batch processing on Kuberbetes\n\n</Caption>\n\n<InlineNotification>\n\n**Note:** where\n\n* NAMESPACE is the namespace where you want to run the batch processing\n* yaml_chart_name is the name of the chart you are creating\n\n</InlineNotification>\n\n### Post batch processing\n\nWhen the batch processes complete, the pods remain behind and are not shut down.\n\nThe batch pods that are created for batch streaming are on demand. After the batch process finishes, the related pods should be destroyed to free resources in the IKS cluster.\n","fileAbsolutePath":"/home/travis/build/IBM/spm-kubernetes/src/pages/07-supporting-infrastructure/batch.mdx"}}}}